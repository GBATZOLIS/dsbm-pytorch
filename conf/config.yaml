# @package _global_

defaults:
  - _self_
  # - launcher: slurm_gpu
  - job
  - model: UNET
  - method: dbdsb  #dsb, dbdsb
  - dataset: mnist_transfer
  - vae: simple
  # - override hydra/launcher: submitit_slurm

nodes: 1
devices: 1
phase: train #options=[train, test]
space: observation #default=[observation, latent]
name: ${Dataset}_${data.dataset}
run_name: None
run: 0
seed: 42
use_default_wandb_name: False
wandb_id: null

# Logging
LOGGER: Wandb
CSV_log_dir: ./

# Training
optimizer: Adam
test_during_training: True
test_batch_size: 1000
plot_level: 1
cache_refresh_stride: ${num_iter}
cache_num_steps: ${num_steps}
test_num_steps: ${num_steps}
test_num_steps_sequence: [25]
normalize_x1: False

# Paths
paths: 
  experiments_dir_name: experiments
  data_dir_name: data

# Checkpoint
autostart_next_it: False
checkpoint_run: False #set it to True if you want to evaluate the model.
checkpoint_it: 1
checkpoint_pass: b  # b or f (skip b ipf run)
checkpoint_iter: 0
checkpoint_dir: null
sample_checkpoint_f: null
sample_checkpoint_b: ${checkpoint_dir}/
checkpoint_f: null
checkpoint_b: ${checkpoint_dir}/
optimizer_checkpoint_f: null
optimizer_checkpoint_b: ${checkpoint_dir}/