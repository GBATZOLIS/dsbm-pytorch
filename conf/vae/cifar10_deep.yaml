# @package _global_


variational: True
latent_dim : 384
kl_weight: 0.01 #if you set decoding to stochastic, make sure to set the training kl_weight correctly. This is the beta value of the Î²-VAE.
tuning_gpus: [0] #gpus used for tuning the kl_weight using the parallel optuna study.
kl_weight_min: 1e-4
kl_weight_max: 1
vae_tuning_freq : 50
n_trials: 5
tuning_fid_feature: 2048
decoding: deterministic


vae_checkpoint_path : None

encoder:
  name: deep_encoder
  ch: 64
  ch_mult: [1, 2, 4]
  num_res_blocks: 2
  attn_resolutions: [16]
  dropout: 0.
  resamp_with_conv: True
  in_channels: ${data.channels}
  resolution: ${data.image_size}
  z_channels: 6 #${latent_dim//(2**(1-len(${encoder.ch_mult})*${data.image_size})
  double_z: ${variational}
  use_linear_attn: False
  attn_type: vanilla
  split_output: True

decoder:
  name: deep_decoder
  ch: 64
  out_ch: ${data.channels}
  ch_mult: [1, 2, 4]
  num_res_blocks: 2
  attn_resolutions: [16]
  dropout: 0.
  resamp_with_conv: True
  in_channels: ${data.channels}
  resolution: ${data.image_size}
  z_channels: 6
  give_pre_end: False
  tanh_out: False
  use_linear_attn: False
  attn_type: vanilla

vae_optim:
  lr: 1e-4
  use_scheduler: True
  sch_factor: 0.9
  sch_patience: 200
  sch_min_lr: 1e-6

early_stopping_patience: 400